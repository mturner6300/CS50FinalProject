Hi! Welcome to our design file! Here we'll take you through how we designed our web application, myharvard2: Electric Boogaloo

Let's start by running through the libraries we installed, and what we installed them for:
flask - this is one of python's best-liked and most-used libraries for hosting dynamic web applications. We use flask to host and run our app.
flask_session - this is an extension library for Flask, which enables the storage of simple pieces of information on the user's device. We use this to remember logged-in accounts, previous searches, search result page numbers, and to flash transient messages to the user about actions they have taken 
flask_paginate - this is an extension library for flask, which enables the storage of large amounts of data, such as search results, over multiple pages, to reduce loading times and improve the appearance of our site, which deals with throusands of courses.
tempfile - this is a library making and managing simple, temporary user-side files, which we use to make temporary directories in which to store sessions
werkzeug.exceptions - this is a library that raises standard error messages for non-200 status responses, which we have used to make dealing with exceptions to http requests a little cleaner and clearer to programmers
werkzeug.security - this is a library that enables some basic security functions in an application, which we use to generate and check hashes
sqlite3 - this is a library used to interface with sqlite databases, which we have used to do just that, allowing us to query our database, adding, retrieving, and removing information either transiently or permanently
random - this is a library used to generate pseudorandom numbers/strings, which we use to generate temporary passwords when one is forgotten. This was not our first choice for this functionality, prefering the secrets library, which uses truer randomness, however, we had some issues requiring extensions for this library late in the development, and decided to use the native random to be able focus on other functionality (the emailing platform). This is a flawed design, but given that it was a temporary password and we wanted to add in other functionality, we were willing to acquiesce for the proof of concept
string - this library adds some basic functionality with strings such as constant lists for ASCII characters which we use to generate our temporary password.
smtplib - this is a library which allows generation of a server for sending and reading emails which we use to send the username and temporary password of a user who has forgotten their username or password.
ssl - this is a library which generates secure contexts for email servers such as smtplib, which we use for an encrypted context for our servers, to add security to our sending of emails.
os - ?
ctypes - ?
requests - a library for retrieving information from http requests
urllib.parse - a library for parsing (separating into constituent parts) urls for easier use
pandas - a library for dealing with importing data which we use with sqlite3 to import our data-scraped data from csv files into our sql database
functools - a library which enables extra ways to reference functions, which we use to 'wrap' functions

Let's first talk about our files that exist outside of our main app.py script. First we have helpers.py which contains a few functions that simplify code that we would have been writing a LOT otherwise or was otherwise verbose needed abstraction for simplicity.
The first of these is login_required, which takes a function as input, which it 'wraps' to allow the following function to proceed only after the function defined by login_required, which, incidentally, checks the sessions directory for a user_id variable, where we will later be storing a user id upon login.
The second is make_cursor, which performs the necessary set up to interface with our sql database, taking the file as input and outfputting the connection obeject which we use to commit local changes permanently to the file, and the cursor object which allows temporary changes to be made and stored locally, which can then be made permanent later if necessary.
Both of these were made because we were intending to use them a lot in the file, so it made most sense to abstract them away.
The final function in helpers.py is refresh placements, which abstracts away the horribly verbose code to retrieve the possible placements for maths, lifesci, and expos by intereacting multiple times with the sql database. While this function is only used twice (I believe?) its almost 40 lines of content made it impossible to read through the accounts route code easily (as accounts also has other functionality) so it made sense to abstract this away, even if we were only to use it twice. It should also be noted that this function would have come in handy if we had stuck to our original design for tracks, which would have dynamically reacted to your placements in tracks (concentrations, secondaries) that change based on your placement (e.g. Bioengineering).

This segues nicely populatedatabase.py, which is the function responsible for the setup and resetting of our database, which was based upon the initial sql file myharvard2, which we initially used to set up our database. We switched to python to maximise the ease with which we could read data from the csv files that our data scraping collected (more on this later), then process them, then add them to the database. We elected to use the pandas library because we had some familiarity with it from other classes, and because it offered functionality that we felt made the data easier to work with, such as the data frame object. After reading the csvfile into a variable, we reformatted it as a data frame with column headers taken from the csv file, which made referencing them and iterating through them much simpler. After connecting to the database, we proceed to drop all the tables in the database, and then remake them according to the architecture we had designed (more on this later). This was suitable, despite losing a lot of data upon this reset, because we were regularly changing the layout of our database, requiring different columns to exist or not to (you will see that there are still one or two redundant tables from ideas we aspired to create but did not realise), and because the data we were inputting during development was either easily accessible, regularly updated like the database, and built in to the populate function (so, the courses, professors, etc.), or minimal data like our own 'accounts' used to test during development, which it was minimal effort to remake upon a reset. If we were to put this product into the world, we would produce another, similar python script called 'updatedatabse.py' or some such, which took arguements as to which precise tables it was resetting/adding to, so that most of the database would be untouched and only small areas that we wanted to update (i.e. adding new classes or new offerings, or minimal changes to architecture) would be affected. Because we were regularly performing overhauls with new classes new tables and new datasrtuctures, this factory reset function to initially set up the database made most sense.

After clearing and remaking the tables in the database, popualate database also manipulates our datascraped data to retrieve what is necessary from each row to fill in each of the tables we were using. Using this for loop sintage looping through each row represented by a tuple in the data frame made sense because it meant we would have access to a single row of data, which we could then split and manipualte each column individually in order to put it into the appropriate table. We demonstrated this multiple times with multiple csv files as it was impossible to datascrape all of the information we needed for tracks and courses all from one place (which was part of our motivation to make this app.) This also gave us the greatest freedom to design our database to maximise its efficiency, which was important as we knew we would be dealing with tens of thousands of pieces of linked data, which even on modern computers can be slow or finicky to process and work with on webpages. After importing the data to the relevant tables, we then performed populations of tables that linked the different pieces of data together based on the relationships in the csv, and the indexes we had established in tables which stored most of the meaningful content of the csv.

This leads on to our database design, which we elected to include in full, despite not being able to realise every aspect of the design and therefore use every aspect of the database. The main table in which courses are stored is courses, which stores their names, codes, and descriptions with an id. These courses can be combined with the ids of professors from the professors table and the sessions/terms ids in the offerings table, which would have been useful had we achieved our initial aim for the tracks page, which was to add a track planner, in which you you plan your track and your classes in that track by requirements and by semester. However, we did not manage to implement this, so the offerings table remains populated but unused. We also struggled to data scrape pre- co- and antirequisites for courses, so those tables that would link a course_id to another course_id that is its pre-, co-, or antirequisite respectively remain created but empty. The completed and favourites tables link a user to a course id for which they have indicated that that course is their favourite, or one they have taken. We considered combining these two tables into one, with a third column indicating whether it is a completed or favourite course, but decided that that would be adding more data that takes up more space, so these separate tables are the most efficient way.  

We datascraped...
